{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import boto3\n",
    "import json\n",
    "import urllib\n",
    "import random\n",
    "import pandas as pd\n",
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below block is used for obtaining an encounter's full audio clip, which you can upload to the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "import predictionhealth as ph\n",
    "from imp import reload\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display as ld\n",
    "import random\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running transcription jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"MedicalTranscriptionJobName\": GenerateJobName(),\n",
    "    \"LanguageCode\": \"en-US\",\n",
    "    \"MediaFormat\": \"wav\",\n",
    "    \"Media\": {\n",
    "        \"MediaFileUri\": \"https://test-transcribe-bartleby.s3.us-east-2.amazonaws.com/youtube_audio_4.wav\"\n",
    "    },\n",
    "    \"OutputBucketName\": \"test-transcribe-bartleby\",\n",
    "    \"Specialty\": \"PRIMARYCARE\",\n",
    "    \"Type\": \"CONVERSATION\",\n",
    "    \"Settings\": {\n",
    "      \"MaxSpeakerLabels\": 3,\n",
    "      \"ShowSpeakerLabels\": True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transcribe = boto3.client('transcribe')\n",
    "job_name = data['MedicalTranscriptionJobName']\n",
    "job_uri = data['Media']['MediaFileUri']\n",
    "\n",
    "start_job(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_job(d):\n",
    "    transcribe.start_medical_transcription_job(\n",
    "        MedicalTranscriptionJobName=d['MedicalTranscriptionJobName'],\n",
    "        LanguageCode=d['LanguageCode'],\n",
    "        MediaFormat=d['MediaFormat'],\n",
    "        Media=d['Media'],\n",
    "        Type=d['Type'],\n",
    "        Specialty=d['Specialty'],\n",
    "        OutputBucketName=d['OutputBucketName'],\n",
    "        Settings=d['Settings']\n",
    "    )\n",
    "    return\n",
    "\n",
    "transcription_number = 0\n",
    "\n",
    "def GenerateJobName():\n",
    "    transcription_number += 1\n",
    "    return 'test-aws-accuracy-'+transcription_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    status = transcribe.get_medical_transcription_job(MedicalTranscriptionJobName=job_name)\n",
    "    if status['MedicalTranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "        break\n",
    "    print(\"Not ready yet...\")\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transcript = urllib.request.urlopen(status['MedicalTranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
    "transcript_as_string = (transcript.read()).decode('utf-8')\n",
    "outfile = open('returned_transcript.json', 'w')\n",
    "outfile.write(transcript_as_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data, creating a model, validating the model, and overwriting transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstructured=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Downloads/test-aws-accuracy-0.json') as json_file:\n",
    "    unstructured.append(json.load(json_file))\n",
    "with open('Downloads/test-aws-accuracy-1.json') as json_file:\n",
    "    unstructured.append(json.load(json_file))\n",
    "with open('Downloads/test-aws-accuracy-2.json') as json_file:\n",
    "    unstructured.append(json.load(json_file))\n",
    "with open('Downloads/test-aws-accuracy-3.json') as json_file:\n",
    "    unstructured.append(json.load(json_file))\n",
    "with open('Downloads/test-aws-accuracy-4.json') as json_file:\n",
    "    unstructured.append(json.load(json_file))\n",
    "with open('Downloads/test-aws-accuracy-5.json') as json_file:\n",
    "    unstructured.append(json.load(json_file))\n",
    "with open('Downloads/test-aws-accuracy-6.json') as json_file:\n",
    "    unstructured.append(json.load(json_file))\n",
    "    \n",
    "with open('Downloads/test-aws-accuracy-7.json') as json_file:\n",
    "    unstructured.append(json.load(json_file))\n",
    "with open('Downloads/test-aws-accuracy-8.json') as json_file:\n",
    "    unstructured.append(json.load(json_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking down the data based on whether it's a clinician or patient speaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {\n",
    "    'clinician': [],\n",
    "    'patient':[],\n",
    "}\n",
    "val = {\n",
    "    'clinician': [],\n",
    "    'patient': [],\n",
    "}\n",
    "p_0 = prepare_encounter_data(unstructured[0], 1)\n",
    "p_1 = prepare_encounter_data(unstructured[1], 0)\n",
    "p_2 = prepare_encounter_data(unstructured[2], 1)\n",
    "p_3 = prepare_encounter_data(unstructured[3], 0)\n",
    "p_4 = prepare_encounter_data(unstructured[4], 1)\n",
    "p_5 = prepare_encounter_data(unstructured[5], 0)\n",
    "p_6 = prepare_encounter_data(unstructured[6], 1)\n",
    "\n",
    "p_7 = prepare_encounter_data(unstructured[7], 0)\n",
    "p_8 = prepare_encounter_data(unstructured[8], 0)\n",
    "\n",
    "\n",
    "train['clinician'].append(p_0['clinician'])\n",
    "train['patient'].append(p_0['patient'])\n",
    "train['clinician'].append(p_1['clinician'])\n",
    "train['patient'].append(p_1['patient'])\n",
    "train['clinician'].append(p_2['clinician'])\n",
    "train['patient'].append(p_2['patient'])\n",
    "train['clinician'].append(p_3['clinician'])\n",
    "train['patient'].append(p_3['patient'])\n",
    "train['clinician'].append(p_4['clinician'])\n",
    "train['patient'].append(p_4['patient'])\n",
    "train['clinician'].append(p_5['clinician'])\n",
    "train['patient'].append(p_5['patient'])\n",
    "train['clinician'].append(p_6['clinician'])\n",
    "train['patient'].append(p_6['patient'])\n",
    "\n",
    "val['clinician'].append((p_7['clinician'], 7))\n",
    "val['patient'].append((p_7['patient'], 7))\n",
    "val['clinician'].append((p_8['clinician'], 8))\n",
    "val['patient'].append((p_8['patient'], 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Downloads/test-aws-accuracy-40.json') as json_file:\n",
    "    uglies = json.load(json_file)\n",
    "res = prepare_encounter_data(uglies,0)\n",
    "train = {\n",
    "    'clinician': [],\n",
    "    'patient': []\n",
    "}\n",
    "train['clinician'] = res['clinician']\n",
    "train['patient'] = res['patient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_encounter_data(data, clinician_index):\n",
    "    word_results = data[\"results\"][\"items\"]\n",
    "    speaker_labels_raw = data[\"results\"][\"speaker_labels\"][\"segments\"]\n",
    "    num_speakers = data[\"results\"][\"speaker_labels\"][\"speakers\"]\n",
    "    speaker_labels = []\n",
    "    for speaker_labels_group in speaker_labels_raw:\n",
    "        speaker_labels = speaker_labels + speaker_labels_group[\"items\"]\n",
    "\n",
    "    speaker_aggregation = {\n",
    "        \"spk_0\": [],\n",
    "        \"spk_1\": [],\n",
    "        \"spk_2\": [],\n",
    "    }\n",
    "    wr_counter = 0\n",
    "    sl_counter = 0\n",
    "    while sl_counter < len(speaker_labels):\n",
    "        if \"start_time\" in word_results[wr_counter]:\n",
    "            speaker_aggregation[speaker_labels[sl_counter][\"speaker_label\"]].append(word_results[wr_counter][\"alternatives\"][0][\"content\"])\n",
    "            sl_counter += 1\n",
    "        else:\n",
    "            speaker_aggregation[speaker_labels[sl_counter][\"speaker_label\"]].append(word_results[wr_counter][\"alternatives\"][0][\"content\"])\n",
    "        wr_counter += 1\n",
    "        \n",
    "    clinician_tag = 'spk_' + str(clinician_index)\n",
    "    if num_speakers == 3:\n",
    "        if clinician_index == 1:\n",
    "            patient_tag_1 = 'spk_' + '0'\n",
    "            patient_tag_2 = 'spk_' + '2'\n",
    "        elif clinician_index == 0:\n",
    "            patient_tag_1 = 'spk_' + '1'\n",
    "            patient_tag_2 = 'spk_' + '2'\n",
    "        else:\n",
    "            patient_tag_1 = 'spk_' + '0'\n",
    "            patient_tag_2 = 'spk_' + '1'\n",
    "        \n",
    "        speaker_data = {\n",
    "            'clinician': speaker_aggregation[clinician_tag],\n",
    "            'patient': speaker_aggregation[patient_tag_1] + speaker_aggregation[patient_tag_2]\n",
    "        }\n",
    "    else:\n",
    "        if clinician_index == 1:\n",
    "            patient_tag_1 = 'spk_' + '0'\n",
    "        elif clinician_index == 0:\n",
    "            patient_tag_1 = 'spk_' + '1'\n",
    "        \n",
    "        speaker_data = {\n",
    "            'clinician': speaker_aggregation[clinician_tag],\n",
    "            'patient': speaker_aggregation[patient_tag_1]\n",
    "        }\n",
    "        \n",
    "    return speaker_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the data as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(\n",
    "    clin_examples, \n",
    "    pt_examples):\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    label_options = [0, 1]\n",
    "    label_names = ['clinician', 'patient']\n",
    "    example_lists = [clin_examples, pt_examples]\n",
    "\n",
    "    for i in range(len(label_options)):\n",
    "        label = label_options[i]\n",
    "        label_name = label_names[i]\n",
    "        example_list = example_lists[i]\n",
    "\n",
    "        for encounter_conversation in example_list:\n",
    "            ex_idx = 0\n",
    "            text = ''\n",
    "            while ex_idx < len(encounter_conversation):\n",
    "                if encounter_conversation[ex_idx] in ['.', '!', '?']:\n",
    "                    text += encounter_conversation[ex_idx]\n",
    "                    temp_row = [text, label, label_name]\n",
    "                    data.append(temp_row)\n",
    "                    text = ''\n",
    "                else:\n",
    "                    text += ' ' + encounter_conversation[ex_idx]\n",
    "                ex_idx += 1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_data(\n",
    "    clin_examples, \n",
    "    pt_examples):\n",
    "    \n",
    "    data = []\n",
    "        \n",
    "    label_options = [0, 1]\n",
    "    label_names = ['clinician', 'patient']\n",
    "    example_lists = [clin_examples, pt_examples]\n",
    "    \n",
    "    percent_lists = [1]\n",
    "\n",
    "    for i in range(len(label_options)):\n",
    "        label = label_options[i]\n",
    "        label_name = label_names[i]\n",
    "        \n",
    "        for example_list in example_lists[i]:\n",
    "            max_index = int(len(example_list[0]))\n",
    "            ex_idx = 0\n",
    "            text = ''\n",
    "            while ex_idx < max_index:\n",
    "                text += ' ' + example_list[0][ex_idx]\n",
    "                ex_idx += 1\n",
    "            temp_row = [text, label, label_name, example_list[1]]\n",
    "            data.append(temp_row)\n",
    "            if i == 1:\n",
    "                min_index = max_index\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = create_training_data(train['clinician'], train['patient'])\n",
    "val = create_validation_data(val['clinician'], val['patient'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_options = ['clinician', 'patient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Counting number of each label before balancing\n",
    "pats = 0\n",
    "clins = 0\n",
    "for element in train:\n",
    "    if element[2] == 'patient':\n",
    "        pats += 1\n",
    "    else:\n",
    "        clins += 1\n",
    "print(pats)\n",
    "print(clins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = balance_and_shuffle_dataset(train, label_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balances the dataframe provided with text samples extracted from data objects with 'text' and 'label' fields \n",
    "# returns dataset with the less common labels randomly oversampled\n",
    "# Groups by label and then resamples with replacement to achieve equal groups\n",
    "# Balances the dataset and returns  dataset with the more common labels randomly undersampled\n",
    "def balance_and_shuffle_dataset(samples, label_options):\n",
    "    \n",
    "    indices_by_label = []\n",
    "    \n",
    "    # Get the counts for the different types of labels\n",
    "    for label in label_options:\n",
    "        \n",
    "        temp_indices = [pair[0] for pair in enumerate(samples) if pair[1][2] == label]\n",
    "        indices_by_label.append(temp_indices)\n",
    "        \n",
    "    # Shuffle time and figure out what's the smallest list\n",
    "    maximum_len = -1\n",
    "    min_len = -1\n",
    "    for index_list in indices_by_label:\n",
    "        \n",
    "        random.shuffle(index_list)\n",
    "        \n",
    "        # Determine the max and min # sample index positions\n",
    "        if maximum_len == -1:\n",
    "            maximum_len = len(index_list)\n",
    "            min_len = len(index_list)\n",
    "        elif len(index_list) > maximum_len:\n",
    "            maximum_len = len(index_list)\n",
    "        if min_len > len(index_list):\n",
    "            min_len = len(index_list)\n",
    "    \n",
    "    # Create a new balanced set and return it\n",
    "    all_indices = []\n",
    "    mult_factor = int((maximum_len - min_len)/min_len)\n",
    "    mult_factor += 1\n",
    "    \n",
    "    for index_list in indices_by_label:\n",
    "        # Handle the special oversample case\n",
    "        if len(index_list) != maximum_len:\n",
    "            all_indices.extend(index_list*mult_factor)\n",
    "        else:\n",
    "            all_indices.extend(index_list)\n",
    "        \n",
    "    random.shuffle(all_indices)\n",
    "        \n",
    "    return [samples[index] for index in all_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### counting labels after balancing\n",
    "pats = 0\n",
    "clins = 0\n",
    "for element in train:\n",
    "    if element[2] == 'patient':\n",
    "        pats += 1\n",
    "    else:\n",
    "        clins += 1\n",
    "print(pats)\n",
    "print(clins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train)\n",
    "train.columns = ['text', 'labels', 'label_names']\n",
    "val = pd.DataFrame(val)\n",
    "val.columns = ['text', 'labels', 'label_names', 'encounter_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ClassificationModel\n",
    "MODEL = ClassificationModel(\n",
    "    'bert', \n",
    "    'bert-base-cased', # can be a path to load a previously trained model\n",
    "    num_labels=2,\n",
    "    args={'reprocess_input_data': True, 'overwrite_output_dir': True},\n",
    "    use_cuda=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "MODEL.train_model(train, output_dir='speaker_label_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loading = ClassificationModel(\n",
    "    \"bert\", \"speaker_label_model/checkpoint-837-epoch-1\", use_cuda=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = MODEL.predict(val['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to assess correct clinician vs patient determination, compare the results between actual clinician and actual patient transcripts for each encounter.\n",
    "### To do this comparison, a summation is done on each row; the more-positive value for each encounter will be the predicted-clinician row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 1]), array([[ 1.0553558, -1.2158972],\n",
       "        [ 1.4158463, -1.1864611],\n",
       "        [-0.5651022,  1.1164746],\n",
       "        [-0.5484368,  1.1450765]], dtype=float32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.271253, 2.6023073]\n",
      "[-1.6815768, -1.6935134]\n"
     ]
    }
   ],
   "source": [
    "# this is after changing training data length to sentences (previously used full encounters)\n",
    "modified_results = [result[0]-result[1] for result in results[1]]\n",
    "print(modified_results[0:int(len(modified_results)/2)])\n",
    "print(modified_results[int(len(modified_results)/2):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method for converting AWS Transcript to PH API type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('<filepath>') as json_file:\n",
    "    text_basis = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is essentially the final format desired for a transcript\n",
    "final_type = {\n",
    "  \"0_count\": 0,\n",
    "  \"1_count\": 0,\n",
    "  \"2_count\": 0,\n",
    "  \"3_count\": 0,\n",
    "  \"4_count\": 0,\n",
    "  \"5_count\": 0,\n",
    "  \"6_count\": 0,\n",
    "  \"7_count\": 0,\n",
    "  \"alternatives\": [],\n",
    "  \"alternatives_lock\": 0,\n",
    "  \"busy_num\": 0,\n",
    "  \"completed_functions\": [],\n",
    "  \"functions\": [],\n",
    "  \"jobID\": \"\",\n",
    "  \"sentences\": [\n",
    "    {\n",
    "      \"compliance_label\": {\n",
    "        \"label\": \"\",\n",
    "        \"labelIndex\": 0,\n",
    "        \"labelVector\": []\n",
    "      },\n",
    "      \"compliance_label_lock\": 0,\n",
    "      \"fam_label\": {},\n",
    "      \"fam_label_lock\": 0,\n",
    "      \"indexedConcepts\": [],\n",
    "      \"originalSentence\": \"\",\n",
    "      \"originalSentence_lock\": 0,\n",
    "      \"sentenceID\": \"\",\n",
    "      \"sentiment\": {\n",
    "        \"label\": \"negative\",\n",
    "        \"labelIndex\": 0,\n",
    "        \"labelVector\": []\n",
    "      },\n",
    "      \"sentiment_lock\": 0,\n",
    "      \"tokens\": [\n",
    "        {\n",
    "          \"acronymConfidence\": 1,\n",
    "          \"asrSource\": \"GCPSpeechRecognition\",\n",
    "          \"endTime\": 1,\n",
    "          \"isAcronym\": false,\n",
    "          \"isPunctuation\": false,\n",
    "          \"isSpace\": false,\n",
    "          \"originalString\": \"This\",\n",
    "          \"speakerConfidence\": 0,\n",
    "          \"speakerTag\": \"0\",\n",
    "          \"startTime\": 0,\n",
    "          \"textConfidence\": 0\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"sentences_lock\": 0,\n",
    "  \"status\": \"Completed\",\n",
    "  \"uri\": \"\",\n",
    "  \"uri_lock\": 0,\n",
    "  \"uris\": [],\n",
    "  \"uris_lock\": 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This call will convert all labels properly for a given file\n",
    "swapped = predict_and_swamp_for_api(text_basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(swapped, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = json.dumps(swapped)\n",
    "f = open(\"output_2_swapped.json\",\"w\")\n",
    "f.write(content)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_swamp_for_api(basis):\n",
    "    consolidated_by_speaker, originalType = consolidate_sentences_by_speaker(basis['sentences'])\n",
    "        \n",
    "    ## preparing data for prediction\n",
    "    second_filter = []\n",
    "    label_options = [0, 1, 2]\n",
    "    if originalType == 'google':\n",
    "        label_names = ['0', '1', '2']\n",
    "        example_lists = [consolidated_by_speaker['0'], consolidated_by_speaker['1'], consolidated_by_speaker['2']]\n",
    "    elif originalType == 'amazon':\n",
    "        label_names = ['spk_0', 'spk_1', 'spk_2']\n",
    "        example_lists = [consolidated_by_speaker['spk_0'], consolidated_by_speaker['spk_1'], consolidated_by_speaker['spk_2']]\n",
    "    \n",
    "    for i in range(len(label_options)):\n",
    "        label = label_options[i]\n",
    "        label_name = label_names[i]\n",
    "        \n",
    "        text = example_lists[i]\n",
    "        temp_row = [text, label, label_name]\n",
    "        second_filter.append(temp_row)\n",
    "\n",
    "    second_filter = pd.DataFrame(second_filter)\n",
    "    second_filter.columns = ['text', 'labels', 'label_names']\n",
    "    \n",
    "    ## predicting\n",
    "    results = MODEL.predict(second_filter['text'])\n",
    "    \n",
    "    modified_results = [result[0]-result[1] for result in results[1]]\n",
    "    print(modified_results)\n",
    "    modified_results = np.asarray(modified_results)\n",
    "    clinician_index = modified_results.argmax()\n",
    "        \n",
    "    ## internalizing which current label is the clinician/patient\n",
    "    if originalType == 'amazon':\n",
    "        clinician_label = 'spk_' + str(clinician_index)\n",
    "    elif originalType == 'google':\n",
    "        clinician_label = str(clinician_index)\n",
    "    \n",
    "    # reassign all token speaker labels\n",
    "    for sentence in basis['sentences']:\n",
    "        for token in sentence['tokens']:\n",
    "            if token['speakerTag'] == clinician_label:\n",
    "                token['speakerTag'] = 'clinician'\n",
    "            else:\n",
    "                token['speakerTag'] = 'patient'\n",
    "\n",
    "    return basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_sentences_by_speaker(sentences):\n",
    "    originalType = ''\n",
    "    googleTags = ['0', '1', '2']\n",
    "    amazonTags = ['spk_0', 'spk_1', 'spk_2']\n",
    "    \n",
    "    if sentences[0]['tokens'][0]['speakerTag'] in googleTags:\n",
    "        originalType = 'google'\n",
    "    elif sentences[0]['tokens'][0]['speakerTag'] in amazonTags:\n",
    "        originalType = 'amazon'\n",
    "        \n",
    "    if originalType == 'amazon':\n",
    "        consolidated = {\n",
    "            'spk_0': '',\n",
    "            'spk_1': '',\n",
    "            'spk_2': ''\n",
    "        }\n",
    "    elif originalType == 'google':\n",
    "        consolidated = {\n",
    "            '0': '',\n",
    "            '1': '',\n",
    "            '2': ''\n",
    "        }\n",
    "        \n",
    "    for sentence in sentences:\n",
    "        for token in sentence['tokens']:\n",
    "            consolidated[token['speakerTag']] += token['originalString'] + ''\n",
    "            \n",
    "    return consolidated, originalType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing overall accuracy for prediction based on taskBoxes pre-labeled as 'clinician'/'patient' (not necessary for building a new model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_id = '<encounter id>'\n",
    "print(actual_id)\n",
    "actual = ph.get_encounter(actual_id, include_audio=True, dataset='<dataset>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([tb.label for tb in actual.taskBoxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ph)\n",
    "print('getting audio clips')\n",
    "actual.audioClips=ph.get_audio_clips([tb.audioID for tb in actual.taskBoxes if tb.audioID], bucket_name='<bucket name>')\n",
    "actual.fullAudioClip=actual.get_full_encounter_audio_clip()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = actual.fullAudioClip\n",
    "ac.play_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining clinician label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('<transcript path name>') as json_file:\n",
    "    comparison = json.load(json_file)\n",
    "comparison = prepare_comparison_data(comparison)\n",
    "comparison = create_comparison_data(comparison['spk_0'], comparison['spk_1'], comparison['spk_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_comparison_data(data):\n",
    "    word_results = data[\"results\"][\"items\"]\n",
    "    speaker_labels_raw = data[\"results\"][\"speaker_labels\"][\"segments\"]\n",
    "    num_speakers = data[\"results\"][\"speaker_labels\"][\"speakers\"]\n",
    "    speaker_labels = []\n",
    "    for speaker_labels_group in speaker_labels_raw:\n",
    "        speaker_labels = speaker_labels + speaker_labels_group[\"items\"]\n",
    "\n",
    "    speaker_aggregation = {\n",
    "        \"spk_0\": [],\n",
    "        \"spk_1\": [],\n",
    "        \"spk_2\": [],\n",
    "    }\n",
    "    wr_counter = 0\n",
    "    sl_counter = 0\n",
    "    while sl_counter < len(speaker_labels):\n",
    "        if \"start_time\" in word_results[wr_counter]:\n",
    "            speaker_aggregation[speaker_labels[sl_counter][\"speaker_label\"]].append(word_results[wr_counter][\"alternatives\"][0][\"content\"])\n",
    "            sl_counter += 1\n",
    "        else:\n",
    "            speaker_aggregation[speaker_labels[sl_counter][\"speaker_label\"]].append(word_results[wr_counter][\"alternatives\"][0][\"content\"])\n",
    "        wr_counter += 1\n",
    "        \n",
    "    return speaker_aggregation    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_data(\n",
    "    spk_0, \n",
    "    spk_1,\n",
    "    spk_2):\n",
    "    \n",
    "    data = []\n",
    "        \n",
    "    label_options = [0, 1, 2]\n",
    "    label_names = ['spk_0', 'spk_1', 'spk_2']\n",
    "    example_lists = [spk_0, spk_1, spk_2]\n",
    "    \n",
    "    for i in range(len(label_options)):\n",
    "        label = label_options[i]\n",
    "        label_name = label_names[i]\n",
    "        \n",
    "        example_list = example_lists[i]\n",
    "        max_index = int(len(example_list))\n",
    "        ex_idx = 0\n",
    "        text = ''\n",
    "        while ex_idx < max_index:\n",
    "            text += ' ' + example_list[ex_idx]\n",
    "            ex_idx += 1\n",
    "        temp_row = [text, label, label_name]\n",
    "        data.append(temp_row)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comparison['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame(comparison)\n",
    "comparison.columns = ['text', 'labels', 'label_names']\n",
    "print(comparison)\n",
    "results = MODEL.predict(comparison['text'])\n",
    "print(results)\n",
    "print()\n",
    "print()\n",
    "modified_results = [result[0]+result[1] for result in results[1]]\n",
    "print(modified_results[0:int(len(modified_results)/2)])\n",
    "print(modified_results[int(len(modified_results)/2):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Downloads/test-aws-accuracy-40.json') as json_file:\n",
    "    timestamps = json.load(json_file)\n",
    "timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using clinician label to reassign labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for segment in timestamps['results']['speaker_labels']['segments']:\n",
    "    if segment['speaker_label'] == 'spk_1':\n",
    "        segment['speaker_label'] = 'clinician'\n",
    "    else:\n",
    "        segment['speaker_label'] = 'patient'\n",
    "    for subsegment in segment['items']:\n",
    "        if subsegment['speaker_label'] == 'spk_1':\n",
    "            subsegment['speaker_label'] = 'clinician'\n",
    "        else:\n",
    "            subsegment['speaker_label'] = 'patient'\n",
    "timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_taskboxes, proportion_time = find_accuracy(timestamps, actual)\n",
    "print(proportion_taskboxes)\n",
    "print(proportion_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_accuracy(transcript, encounter):\n",
    "    running_duration = 0\n",
    "    comparison_duration = 0\n",
    "    correct_duration = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    transcript_segments = timestamps['results']['speaker_labels']['segments']\n",
    "    \n",
    "    taskboxes = encounter.taskBoxes\n",
    "    labels = [tb.label for tb in taskboxes]\n",
    "    print(labels)\n",
    "    for idx in range(len(taskboxes)):\n",
    "        running_duration += taskboxes[idx].duration\n",
    "        print(running_duration)\n",
    "        \n",
    "        if labels[idx] not in [None, 'None', 'both', 'Other', 'other', 'Both', 'ambient']:\n",
    "            if labels[idx] == find_transcript_label(transcript_segments, taskboxes[idx].duration, running_duration, True):\n",
    "                correct_duration += taskboxes[idx].duration\n",
    "                correct += 1\n",
    "            comparison_duration += taskboxes[idx].duration\n",
    "            print(labels[idx])\n",
    "            print(find_transcript_label(transcript_segments, taskboxes[idx].duration, running_duration, False))\n",
    "            total += 1\n",
    "            \n",
    "    return correct/total, correct_duration/comparison_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_transcript_label(ts, duration, total_time, print_req):\n",
    "    time_target = total_time-duration/2\n",
    "    if print_req:\n",
    "        print(time_target)\n",
    "    for idx in range(len(ts)):\n",
    "        if time_target >= float(ts[idx]['start_time']) and time_target <= float(ts[idx]['end_time']):\n",
    "            return ts[idx]['speaker_label']\n",
    "        elif time_target < float(ts[idx]['start_time']) and time_target > float(ts[idx-1]['end_time']):\n",
    "            return ts[idx]['speaker_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing speed of AWS Non-Medical Transcription (unrelated to anything above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TranscriptionJob': {'TranscriptionJobName': 'test-non-medical-3',\n",
       "  'TranscriptionJobStatus': 'IN_PROGRESS',\n",
       "  'LanguageCode': 'en-US',\n",
       "  'MediaFormat': 'wav',\n",
       "  'Media': {'MediaFileUri': 'https://test-transcribe-bartleby.s3.us-east-2.amazonaws.com/demo.wav'},\n",
       "  'StartTime': datetime.datetime(2020, 7, 31, 11, 23, 28, 477000, tzinfo=tzlocal()),\n",
       "  'CreationTime': datetime.datetime(2020, 7, 31, 11, 23, 28, 454000, tzinfo=tzlocal()),\n",
       "  'Settings': {'ShowSpeakerLabels': True, 'MaxSpeakerLabels': 3}},\n",
       " 'ResponseMetadata': {'RequestId': 'dd8ff2ea-a765-4f1d-a72e-3715803ecfea',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Fri, 31 Jul 2020 16:23:27 GMT',\n",
       "   'x-amzn-requestid': 'dd8ff2ea-a765-4f1d-a72e-3715803ecfea',\n",
       "   'content-length': '364',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"TranscriptionJobName\": \"test-non-medical-3\",\n",
    "    \"LanguageCode\": \"en-US\",\n",
    "    \"MediaFormat\": \"wav\",\n",
    "    \"Media\": {\n",
    "        \"MediaFileUri\": \"https://test-transcribe-bartleby.s3.us-east-2.amazonaws.com/demo.wav\"\n",
    "    },\n",
    "    \"OutputBucketName\": \"test-transcribe-bartleby\",\n",
    "    \"Settings\": {\n",
    "      \"MaxSpeakerLabels\": 3,\n",
    "      \"ShowSpeakerLabels\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "transcribe = boto3.client('transcribe')\n",
    "job_name = data['TranscriptionJobName']\n",
    "job_uri = data['Media']['MediaFileUri']\n",
    "\n",
    "transcribe.start_transcription_job(\n",
    "    TranscriptionJobName=job_name,\n",
    "    LanguageCode=data['LanguageCode'],\n",
    "    MediaFormat=data['MediaFormat'],\n",
    "    Media=data['Media'],\n",
    "    OutputBucketName=data['OutputBucketName'],\n",
    "    Settings=data['Settings']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "{'TranscriptionJob': {'TranscriptionJobName': 'test-non-medical-3', 'TranscriptionJobStatus': 'COMPLETED', 'LanguageCode': 'en-US', 'MediaSampleRateHertz': 44100, 'MediaFormat': 'wav', 'Media': {'MediaFileUri': 'https://test-transcribe-bartleby.s3.us-east-2.amazonaws.com/demo.wav'}, 'Transcript': {'TranscriptFileUri': 'https://s3.us-east-2.amazonaws.com/test-transcribe-bartleby/test-non-medical-3.json'}, 'StartTime': datetime.datetime(2020, 7, 31, 11, 23, 28, 477000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2020, 7, 31, 11, 23, 28, 454000, tzinfo=tzlocal()), 'CompletionTime': datetime.datetime(2020, 7, 31, 11, 25, 18, 432000, tzinfo=tzlocal()), 'Settings': {'ShowSpeakerLabels': True, 'MaxSpeakerLabels': 3, 'ChannelIdentification': False, 'ShowAlternatives': False}}, 'ResponseMetadata': {'RequestId': 'e8e60c6e-e4ec-4065-883b-8725b994e682', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Fri, 31 Jul 2020 16:25:21 GMT', 'x-amzn-requestid': 'e8e60c6e-e4ec-4065-883b-8725b994e682', 'x-amzn-transcribe-store-audio': 'false', 'content-length': '601', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    status = transcribe.get_transcription_job(TranscriptionJobName=\"test-non-medical-3\")\n",
    "    if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "        break\n",
    "    print(\"Not ready yet...\")\n",
    "    time.sleep(5)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TranscriptionJob': {'TranscriptionJobName': 'test-non-medical-7',\n",
       "  'TranscriptionJobStatus': 'IN_PROGRESS',\n",
       "  'LanguageCode': 'en-US',\n",
       "  'MediaFormat': 'wav',\n",
       "  'Media': {'MediaFileUri': 'https://test-transcribe-bartleby.s3.us-east-2.amazonaws.com/download+(10).wav'},\n",
       "  'StartTime': datetime.datetime(2020, 7, 31, 12, 37, 16, 572000, tzinfo=tzlocal()),\n",
       "  'CreationTime': datetime.datetime(2020, 7, 31, 12, 37, 16, 544000, tzinfo=tzlocal()),\n",
       "  'Settings': {'ShowSpeakerLabels': True, 'MaxSpeakerLabels': 3}},\n",
       " 'ResponseMetadata': {'RequestId': '6d99f6cb-cfc4-4e01-ac14-38313a8222d5',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Fri, 31 Jul 2020 17:37:16 GMT',\n",
       "   'x-amzn-requestid': '6d99f6cb-cfc4-4e01-ac14-38313a8222d5',\n",
       "   'content-length': '373',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"TranscriptionJobName\": \"test-non-medical-7\",\n",
    "    \"LanguageCode\": \"en-US\",\n",
    "    \"MediaFormat\": \"wav\",\n",
    "    \"Media\": {\n",
    "        \"MediaFileUri\": \"https://test-transcribe-bartleby.s3.us-east-2.amazonaws.com/download+(10).wav\"\n",
    "    },\n",
    "    \"OutputBucketName\": \"test-transcribe-bartleby\",\n",
    "    \"Settings\": {\n",
    "      \"MaxSpeakerLabels\": 3,\n",
    "      \"ShowSpeakerLabels\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "transcribe = boto3.client('transcribe')\n",
    "job_name = data['TranscriptionJobName']\n",
    "job_uri = data['Media']['MediaFileUri']\n",
    "\n",
    "transcribe.start_transcription_job(\n",
    "    TranscriptionJobName=job_name,\n",
    "    LanguageCode=data['LanguageCode'],\n",
    "    MediaFormat=data['MediaFormat'],\n",
    "    Media=data['Media'],\n",
    "    OutputBucketName=data['OutputBucketName'],\n",
    "    Settings=data['Settings']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "{'TranscriptionJob': {'TranscriptionJobName': 'test-non-medical-7', 'TranscriptionJobStatus': 'COMPLETED', 'LanguageCode': 'en-US', 'MediaSampleRateHertz': 44100, 'MediaFormat': 'wav', 'Media': {'MediaFileUri': 'https://test-transcribe-bartleby.s3.us-east-2.amazonaws.com/download+(10).wav'}, 'Transcript': {'TranscriptFileUri': 'https://s3.us-east-2.amazonaws.com/test-transcribe-bartleby/test-non-medical-7.json'}, 'StartTime': datetime.datetime(2020, 7, 31, 12, 37, 16, 572000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2020, 7, 31, 12, 37, 16, 544000, tzinfo=tzlocal()), 'CompletionTime': datetime.datetime(2020, 7, 31, 12, 40, 46, 548000, tzinfo=tzlocal()), 'Settings': {'ShowSpeakerLabels': True, 'MaxSpeakerLabels': 3, 'ChannelIdentification': False, 'ShowAlternatives': False}}, 'ResponseMetadata': {'RequestId': '9461e8fa-01bb-4722-bf6e-156759e3dd81', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Fri, 31 Jul 2020 17:40:47 GMT', 'x-amzn-requestid': '9461e8fa-01bb-4722-bf6e-156759e3dd81', 'x-amzn-transcribe-store-audio': 'false', 'content-length': '610', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    status = transcribe.get_transcription_job(TranscriptionJobName=\"test-non-medical-7\")\n",
    "    if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "        break\n",
    "    print(\"Not ready yet...\")\n",
    "    time.sleep(5)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TranscriptionJob': {'TranscriptionJobName': 'test-non-medical-5',\n",
       "  'TranscriptionJobStatus': 'IN_PROGRESS',\n",
       "  'LanguageCode': 'en-US',\n",
       "  'MediaFormat': 'wav',\n",
       "  'Media': {'MediaFileUri': 'https://test-transcribe-bartleby.s3.us-east-2.amazonaws.com/download+(17).wav'},\n",
       "  'StartTime': datetime.datetime(2020, 7, 31, 11, 30, 19, 469000, tzinfo=tzlocal()),\n",
       "  'CreationTime': datetime.datetime(2020, 7, 31, 11, 30, 19, 447000, tzinfo=tzlocal()),\n",
       "  'Settings': {'ShowSpeakerLabels': True, 'MaxSpeakerLabels': 3}},\n",
       " 'ResponseMetadata': {'RequestId': '8444613d-829a-4d4e-bc9c-93f15bb413bf',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Fri, 31 Jul 2020 16:30:18 GMT',\n",
       "   'x-amzn-requestid': '8444613d-829a-4d4e-bc9c-93f15bb413bf',\n",
       "   'content-length': '373',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"TranscriptionJobName\": \"test-non-medical-5\",\n",
    "    \"LanguageCode\": \"en-US\",\n",
    "    \"MediaFormat\": \"wav\",\n",
    "    \"Media\": {\n",
    "        \"MediaFileUri\": \"https://test-transcribe-bartleby.s3.us-east-2.amazonaws.com/download+(17).wav\"\n",
    "    },\n",
    "    \"OutputBucketName\": \"test-transcribe-bartleby\",\n",
    "    \"Settings\": {\n",
    "      \"MaxSpeakerLabels\": 3,\n",
    "      \"ShowSpeakerLabels\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "transcribe = boto3.client('transcribe')\n",
    "job_name = data['TranscriptionJobName']\n",
    "job_uri = data['Media']['MediaFileUri']\n",
    "\n",
    "transcribe.start_transcription_job(\n",
    "    TranscriptionJobName=job_name,\n",
    "    LanguageCode=data['LanguageCode'],\n",
    "    MediaFormat=data['MediaFormat'],\n",
    "    Media=data['Media'],\n",
    "    OutputBucketName=data['OutputBucketName'],\n",
    "    Settings=data['Settings']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "{'TranscriptionJob': {'TranscriptionJobName': 'test-non-medical-5', 'TranscriptionJobStatus': 'COMPLETED', 'LanguageCode': 'en-US', 'MediaSampleRateHertz': 44100, 'MediaFormat': 'wav', 'Media': {'MediaFileUri': 'https://test-transcribe-bartleby.s3.us-east-2.amazonaws.com/download+(17).wav'}, 'Transcript': {'TranscriptFileUri': 'https://s3.us-east-2.amazonaws.com/test-transcribe-bartleby/test-non-medical-5.json'}, 'StartTime': datetime.datetime(2020, 7, 31, 11, 30, 19, 469000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2020, 7, 31, 11, 30, 19, 447000, tzinfo=tzlocal()), 'CompletionTime': datetime.datetime(2020, 7, 31, 11, 34, 37, 608000, tzinfo=tzlocal()), 'Settings': {'ShowSpeakerLabels': True, 'MaxSpeakerLabels': 3, 'ChannelIdentification': False, 'ShowAlternatives': False}}, 'ResponseMetadata': {'RequestId': '79fa69bf-2dcf-4d68-8bdc-d8292a151916', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Fri, 31 Jul 2020 16:34:39 GMT', 'x-amzn-requestid': '79fa69bf-2dcf-4d68-8bdc-d8292a151916', 'x-amzn-transcribe-store-audio': 'false', 'content-length': '610', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    status = transcribe.get_transcription_job(TranscriptionJobName=\"test-non-medical-5\")\n",
    "    if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "        break\n",
    "    print(\"Not ready yet...\")\n",
    "    time.sleep(5)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TranscriptionJob': {'TranscriptionJobName': 'test-non-medical-8',\n",
       "  'TranscriptionJobStatus': 'IN_PROGRESS',\n",
       "  'LanguageCode': 'en-US',\n",
       "  'MediaFormat': 'mp3',\n",
       "  'Media': {'MediaFileUri': 'https://test-transcribe-bartleby.s3.us-east-2.amazonaws.com/fake-apppointment-2.mp3'},\n",
       "  'StartTime': datetime.datetime(2020, 7, 31, 15, 40, 27, 205000, tzinfo=tzlocal()),\n",
       "  'CreationTime': datetime.datetime(2020, 7, 31, 15, 40, 27, 178000, tzinfo=tzlocal()),\n",
       "  'Settings': {'ShowSpeakerLabels': True, 'MaxSpeakerLabels': 3}},\n",
       " 'ResponseMetadata': {'RequestId': '2673b8f1-12dd-4da4-adb3-9a6e2a633a3c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Fri, 31 Jul 2020 20:40:27 GMT',\n",
       "   'x-amzn-requestid': '2673b8f1-12dd-4da4-adb3-9a6e2a633a3c',\n",
       "   'content-length': '379',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"TranscriptionJobName\": \"test-non-medical-8\",\n",
    "    \"LanguageCode\": \"en-US\",\n",
    "    \"MediaFormat\": \"mp3\",\n",
    "    \"Media\": {\n",
    "        \"MediaFileUri\": \"https://test-transcribe-bartleby.s3.us-east-2.amazonaws.com/fake-apppointment-2.mp3\"\n",
    "    },\n",
    "    \"OutputBucketName\": \"test-transcribe-bartleby\",\n",
    "    \"Settings\": {\n",
    "      \"MaxSpeakerLabels\": 3,\n",
    "      \"ShowSpeakerLabels\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "transcribe = boto3.client('transcribe')\n",
    "job_name = data['TranscriptionJobName']\n",
    "job_uri = data['Media']['MediaFileUri']\n",
    "\n",
    "transcribe.start_transcription_job(\n",
    "    TranscriptionJobName=job_name,\n",
    "    LanguageCode=data['LanguageCode'],\n",
    "    MediaFormat=data['MediaFormat'],\n",
    "    Media=data['Media'],\n",
    "    OutputBucketName=data['OutputBucketName'],\n",
    "    Settings=data['Settings']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "{'TranscriptionJob': {'TranscriptionJobName': 'test-non-medical-8', 'TranscriptionJobStatus': 'COMPLETED', 'LanguageCode': 'en-US', 'MediaSampleRateHertz': 44100, 'MediaFormat': 'mp3', 'Media': {'MediaFileUri': 'https://test-transcribe-bartleby.s3.us-east-2.amazonaws.com/fake-apppointment-2.mp3'}, 'Transcript': {'TranscriptFileUri': 'https://s3.us-east-2.amazonaws.com/test-transcribe-bartleby/test-non-medical-8.json'}, 'StartTime': datetime.datetime(2020, 7, 31, 15, 40, 27, 205000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2020, 7, 31, 15, 40, 27, 178000, tzinfo=tzlocal()), 'CompletionTime': datetime.datetime(2020, 7, 31, 15, 43, 4, 786000, tzinfo=tzlocal()), 'Settings': {'ShowSpeakerLabels': True, 'MaxSpeakerLabels': 3, 'ChannelIdentification': False, 'ShowAlternatives': False}}, 'ResponseMetadata': {'RequestId': '993fa6c9-6f6b-4e3e-832c-f333557e44a4', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Fri, 31 Jul 2020 20:43:08 GMT', 'x-amzn-requestid': '993fa6c9-6f6b-4e3e-832c-f333557e44a4', 'x-amzn-transcribe-store-audio': 'false', 'content-length': '616', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    status = transcribe.get_transcription_job(TranscriptionJobName=\"test-non-medical-8\")\n",
    "    if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "        break\n",
    "    print(\"Not ready yet...\")\n",
    "    time.sleep(5)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
